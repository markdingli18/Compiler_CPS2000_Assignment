{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, token_type, lexeme):\n",
    "        self.token_type = token_type\n",
    "        self.lexeme = lexeme\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.token_type}({self.lexeme})\"\n",
    "    \n",
    "###########################################################################################################################################\n",
    "\n",
    "class Lexer:\n",
    "    def __init__(self, source_code):\n",
    "        self.source_code = source_code\n",
    "        self.transition_table = self.build_transition_table()\n",
    "        self.current_state = 0\n",
    "        self.position = 0\n",
    "        \n",
    "    def build_transition_table(self):\n",
    "        transition_table = {}\n",
    "\n",
    "        states = range(23)\n",
    "        input_characters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-*/%=<>!#&|()[]{},.;:'\\\" \\t\\n\"\n",
    "\n",
    "        for state in states:\n",
    "            for char in input_characters:\n",
    "                transition_table[(state, char)] = -1\n",
    "\n",
    "        # Transitions for identifiers\n",
    "        for char in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "            transition_table[(0, char)] = 1\n",
    "        for char in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\":\n",
    "            transition_table[(1, char)] = 1\n",
    "\n",
    "        # Transitions for integer literals\n",
    "        for char in \"0123456789\":\n",
    "            transition_table[(0, char)] = 2\n",
    "            transition_table[(2, char)] = 2\n",
    "\n",
    "        # Transitions for float literals\n",
    "        transition_table[(2, '.')] = 3\n",
    "        for char in \"0123456789\":\n",
    "            transition_table[(3, char)] = 3\n",
    "\n",
    "        # Transitions for operators\n",
    "        operators = \"+-*/%\"\n",
    "        for op in operators:\n",
    "            transition_table[(0, op)] = 4\n",
    "\n",
    "        # Transitions for delimiters\n",
    "        delimiters = \"(){},.;\"\n",
    "        for delimiter in delimiters:\n",
    "            transition_table[(0, delimiter)] = 5\n",
    "\n",
    "        # Transitions for relational operators\n",
    "        transition_table[(0, '=')] = 6\n",
    "        transition_table[(6, '=')] = 7\n",
    "\n",
    "        transition_table[(0, '!')] = 8\n",
    "        transition_table[(8, '=')] = 9\n",
    "\n",
    "        transition_table[(0, '<')] = 10\n",
    "        transition_table[(10, '=')] = 11\n",
    "\n",
    "        transition_table[(0, '>')] = 12\n",
    "        transition_table[(12, '=')] = 13\n",
    "\n",
    "        # Transitions for colour literals\n",
    "        transition_table[(0, '#')] = 14\n",
    "        for char in \"0123456789abcdefABCDEF\":\n",
    "            transition_table[(14, char)] = 15\n",
    "            transition_table[(15, char)] = 16\n",
    "            transition_table[(16, char)] = 17\n",
    "            transition_table[(17, char)] = 18\n",
    "            transition_table[(18, char)] = 19\n",
    "            transition_table[(19, char)] = 19\n",
    "\n",
    "        # Transitions for whitespace\n",
    "        for char in \" \\t\\n\":\n",
    "            transition_table[(0, char)] = 20\n",
    "            transition_table[(20, char)] = 20\n",
    "\n",
    "        return transition_table\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "    def finalize_token(self, state, lexeme):\n",
    "        token_type = self.get_token_type_from_state(state)\n",
    "        if token_type == \"Identifier\":\n",
    "            keywords = [\"draw\", \"if\", \"else\", \"while\", \"true\", \"false\"]\n",
    "            if lexeme in keywords:\n",
    "                return Token(\"Keyword\", lexeme)\n",
    "            elif lexeme == \"true\" or lexeme == \"false\":\n",
    "                return Token(\"BooleanLiteral\", lexeme)\n",
    "            else:\n",
    "                return Token(token_type, lexeme)\n",
    "        else:\n",
    "            return Token(token_type, lexeme)\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "    def get_next_char(self):\n",
    "        if self.position < len(self.source_code):\n",
    "            # Get the character at the current position in the source code\n",
    "            char = self.source_code[self.position]\n",
    "            # Increment the position to move to the next character\n",
    "            self.position += 1\n",
    "            return char\n",
    "        else:\n",
    "            # Return None if the end of the source code has been reached\n",
    "            return None\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "    def get_token(self):\n",
    "        lexeme = \"\"\n",
    "\n",
    "        while True:\n",
    "            char = self.get_next_char()\n",
    "\n",
    "            if char is None:\n",
    "                if self.current_state == 0:\n",
    "                    return None\n",
    "                elif self.current_state == 1:\n",
    "                    return Token(\"Identifier\", lexeme)\n",
    "                elif self.current_state == 2:\n",
    "                    return Token(\"IntegerLiteral\", lexeme)\n",
    "                elif self.current_state == 3:\n",
    "                    return Token(\"FloatLiteral\", lexeme)\n",
    "                elif self.current_state == 4:\n",
    "                    return Token(\"Operator\", lexeme)\n",
    "                elif self.current_state == 5:\n",
    "                    return Token(\"Delimiter\", lexeme)\n",
    "                elif self.current_state in [7, 9, 11, 13]:\n",
    "                    return Token(\"RelationalOp\", lexeme)\n",
    "                elif self.current_state == 19:\n",
    "                    return Token(\"ColourLiteral\", lexeme)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected state: {self.current_state}\")\n",
    "\n",
    "            next_state = self.transition_table[(self.current_state, char)]\n",
    "\n",
    "            if next_state == -1:\n",
    "                if self.current_state == 1:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"Identifier\", lexeme)\n",
    "                elif self.current_state == 2:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"IntegerLiteral\", lexeme)\n",
    "                elif self.current_state == 3:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"FloatLiteral\", lexeme)\n",
    "                elif self.current_state == 4:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"Operator\", lexeme)\n",
    "                elif self.current_state == 5:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"Delimiter\", lexeme)\n",
    "                elif self.current_state in [7, 9, 11, 13]:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"RelationalOp\", lexeme)\n",
    "                elif self.current_state == 19:\n",
    "                    self.position -= 1\n",
    "                    return Token(\"ColourLiteral\", lexeme)\n",
    "                elif self.current_state == 20:\n",
    "                    self.current_state = 0\n",
    "                    lexeme = \"\"\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected state: {self.current_state}\")\n",
    "            else:\n",
    "                lexeme += char\n",
    "                self.current_state = next_state\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "    def get_token_type_from_state(self, state):\n",
    "        if state == 1:\n",
    "            return \"Identifier\"\n",
    "        elif state == 2:\n",
    "            return \"IntegerLiteral\"\n",
    "        elif state == 3:\n",
    "            return \"FloatLiteral\"\n",
    "        elif state == 4:\n",
    "            return \"Operator\"\n",
    "        elif state == 5:\n",
    "            return \"Delimiter\"\n",
    "        elif state in [7, 9, 11, 13]:\n",
    "            return \"RelationalOp\"\n",
    "        elif state == 19:\n",
    "            return \"ColourLiteral\"\n",
    "        elif state in range(26, 32):\n",
    "            return \"Keyword\"\n",
    "        elif state in [23, 24]:\n",
    "            return \"BooleanLiteral\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def tokenize(self):\n",
    "        tokens = []\n",
    "        while True:\n",
    "            token = self.get_token()\n",
    "            if token is None or token.token_type == \"END\":\n",
    "                break\n",
    "            if token.token_type != \"WHITESPACE\":  # Exclude whitespace tokens\n",
    "                tokens.append(token)\n",
    "        return tokens\n",
    "\n",
    "###########################################################################################################################################\n",
    "\n",
    "source_code = \"10\"\n",
    "lexer = Lexer(source_code)\n",
    "tokens = lexer.tokenize()\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bc10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
